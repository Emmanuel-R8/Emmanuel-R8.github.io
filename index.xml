<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Back2Numbers</title>
    <link>/</link>
    <description>Recent content on Back2Numbers</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-au</language>
    <lastBuildDate>Wed, 23 Oct 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Neural Network - Incremental Growth </title>
      <link>/post/neural-network-incremental-growth.html</link>
      <pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/neural-network-incremental-growth.html</guid>
      <description>|  | DRAFT 1  | This post is first and foremost asking for assistance. Is anything blatantly incorrect? If not, can anybody point to existing articles/posts/litterature?
We all have laptops. But le’ts face it, even in times of 32GB of RAM and NVMe2 drives, forget about running any interesting TensorFlow model. You need to get an external GPU, build your own rig, or very quickly pay a small fortune for cloud instances.</description>
    </item>
    
    <item>
      <title>HarvardX Data Science course - First final project</title>
      <link>/post/harvardx-data-science-course-first-final-project.html</link>
      <pubDate>Sat, 05 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/harvardx-data-science-course-first-final-project.html</guid>
      <description>I recently finished to penultimate final assignment for the HarvardX Data Science course. The Stanford course was clearly machine learning. This one is definitely lighter on the machine learning and much heavier on the data science: how to source, clean and visualise data are key skills. The targeted knowledge is more traditional probabilities/statistics. Long-existing fundamental techniques like inference, polling are there.
This time R is the centre tool of the course.</description>
    </item>
    
    <item>
      <title>Stanford Online - Machine Learning C229 </title>
      <link>/post/stanford-online-machine-learning-c229.html</link>
      <pubDate>Fri, 02 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/stanford-online-machine-learning-c229.html</guid>
      <description>Review I recently completed the Stanford online version of the Machine Learning CS229 course taught by Andrew Ng. There is no need to introduce this course which has reached stardom.
It often was a trip a trip down memory lane repeating what I studied in the late 90’ies. It was interesting that quite a bit has remained as relevant. Back then, and I am now talking early 90ies, neural networks were still fashionable but computationally intractable past what would hardly be considered a single layer nowadays.</description>
    </item>
    
    <item>
      <title>Hello Blogdown!</title>
      <link>/post/2019-08-01-blogdown.html</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-08-01-blogdown.html</guid>
      <description>Blogdown I have been a happy user of R markdown and bookdown developed by Yixui Xie. When I decided to start this blog, giving blogdown a try was a no-brainer. To be honest, it was not my first choice. Jekyll was #1 given it’s good support by GitHub pages. Then I took a dive with Pelican. Both are impressive, but both brought equally painful theming: the base theme sort of works, and only sort of, but anyway was not what I wanted.</description>
    </item>
    
    <item>
      <title>About this site</title>
      <link>/about.html</link>
      <pubDate>Mon, 15 Jul 2019 21:48:51 -0700</pubDate>
      
      <guid>/about.html</guid>
      <description>This blog/website is generated by blogdown R package with its standard Hugo backend. Everything is edited under RStudio.</description>
    </item>
    
    <item>
      <title></title>
      <link>/whoami.html</link>
      <pubDate>Mon, 15 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/whoami.html</guid>
      <description>#&amp;gt;whoami - Thank you Gödel, Escher and Bach! My education was completely scientific with a couple of engineering degrees with a particular passion for mathematics. Add to that a life-long fascination for artificial intelligence. I can trace that back to reading a particular birthday present: Gödel, Escher and Bach. This book held me riveted at 17.
BUT….
But travelling and discovering the planet was a powerful magnet that I could not resist and it turned out that banking and finance first gave me that opportunity.</description>
    </item>
    
  </channel>
</rss>